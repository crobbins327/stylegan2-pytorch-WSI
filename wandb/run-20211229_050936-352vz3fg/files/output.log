
































d: 0.6907; g: 8.0685; r1: 0.0000; path: 0.1753; mean path: 0.0631; augment: 0.0001:   0% 32/800000 [01:22<575:17:57,  2.59s/it]
Traceback (most recent call last):
  File "train.py", line 559, in <module>
    train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, device)
  File "train.py", line 238, in train
    g_optim.step()
  File "/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py", line 119, in step
    group['eps']
  File "/usr/local/lib/python3.7/dist-packages/torch/optim/functional.py", line 87, in adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)
KeyboardInterrupt